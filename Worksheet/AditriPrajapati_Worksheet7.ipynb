{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Concepts and Technologies of AI.\n",
        "Linear Models, Regularization and Cross-Validation"
      ],
      "metadata": {
        "id": "OTurE6Bug-5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Required Libraries"
      ],
      "metadata": {
        "id": "jA3VviVhhgPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical computation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset loading\n",
        "from sklearn.datasets import fetch_openml, load_breast_cancer\n",
        "\n",
        "# Model selection and evaluation\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
        "\n",
        "# Feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "metadata": {
        "id": "JSxqFxUximfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 1: REGRESSION (CALIFORNIA HOUSING)"
      ],
      "metadata": {
        "id": "mczk0TDdbHv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset (OpenML Workaround)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hqFBRcRzbMPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load California Housing dataset from OpenML\n",
        "X, y = fetch_openml(\n",
        "    name=\"california_housing\",\n",
        "    version=1,\n",
        "    as_frame=True,\n",
        "    return_X_y=True\n",
        ")\n",
        "\n",
        "# Combine features and target into a single DataFrame\n",
        "df = X.copy()\n",
        "df[\"MedHouseVal\"] = y\n",
        "\n",
        "# Create average-based features (feature engineering)\n",
        "df[\"AveRooms\"]  = df[\"total_rooms\"] / df[\"households\"]\n",
        "df[\"AveBedrms\"] = df[\"total_bedrooms\"] / df[\"households\"]\n",
        "df[\"AveOccup\"]  = df[\"population\"] / df[\"households\"]\n",
        "\n",
        "# Select only relevant columns\n",
        "df = df[\n",
        "    [\n",
        "        \"median_income\",\n",
        "        \"housing_median_age\",\n",
        "        \"AveRooms\",\n",
        "        \"AveBedrms\",\n",
        "        \"population\",\n",
        "        \"AveOccup\",\n",
        "        \"latitude\",\n",
        "        \"longitude\",\n",
        "        \"MedHouseVal\"\n",
        "    ]\n",
        "]\n",
        "\n",
        "# Remove missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(\"MedHouseVal\", axis=1)\n",
        "y = df[\"MedHouseVal\"]\n",
        "\n",
        "# Train-test split (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "WTzJvnPDkmCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Baseline Linear Regression (No Regularization)"
      ],
      "metadata": {
        "id": "ZAY_3Ao4cP7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose :\n",
        "\n",
        "Establish a baseline\n",
        "\n",
        "Observe coefficients\n",
        "\n",
        "Measure overfitting risk"
      ],
      "metadata": {
        "id": "FpOEhswktJlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Linear Regression model (no regularization)\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Train model on training data\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on training and test data\n",
        "y_train_pred = linear_model.predict(X_train)\n",
        "y_test_pred = linear_model.predict(X_test)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(\"Baseline Linear Regression\")\n",
        "print(\"Training MSE:\", train_mse)\n",
        "print(\"Test MSE:\", test_mse)\n",
        "\n",
        "# Display model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "print(linear_model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acc0Td88cReV",
        "outputId": "b9f47f9e-fd4c-48fb-e4ad-e0ef61654c04"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Linear Regression\n",
            "Training MSE: 0.051601906634910176\n",
            "Test MSE: 0.0641088624702943\n",
            "Model Coefficients:\n",
            "[ 1.97130218e-01 -2.79472278e-03 -2.27758664e-02 -3.28622398e-04\n",
            "  4.11490191e-01  5.00171192e+00 -1.00587030e+00 -4.91570446e+00\n",
            "  3.38393701e-01 -5.81425644e+00 -4.32261922e-01  1.26325368e-02\n",
            "  8.24736376e-03  1.24507529e-03 -1.80785086e+01  2.20798677e+00\n",
            "  4.27375913e+00 -1.81589526e+01  1.19449435e+00  3.01203668e+00\n",
            " -2.14438989e-01 -9.61718848e-03  8.71176397e-03  9.61253395e-04\n",
            " -1.32384962e-01 -7.62670138e-01 -6.15742798e-01  1.32619828e+00\n",
            " -1.02113249e+00 -1.27363832e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation (Baseline Model) :\n",
        "\n",
        "Linear Regression minimizes residual sum of squares\n",
        "\n",
        "No penalty → high variance\n",
        "\n",
        "Large coefficients → risk of overfitting\n",
        "\n",
        "Serves as reference point for Ridge and Lasso"
      ],
      "metadata": {
        "id": "q8JuwXJQe5zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning (Ridge & Lasso)"
      ],
      "metadata": {
        "id": "N5xuNFv_hw3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Hyperparameter Tuning?\n",
        "\n",
        "Regularization strength (alpha) controls:\n",
        "\n",
        "* Bias\n",
        "* Variance\n",
        "\n",
        "* Model complexity"
      ],
      "metadata": {
        "id": "Rg1ZGSEvtV9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Scaling?\n",
        "\n",
        "Regularization is scale-sensitive, so we use StandardScaler."
      ],
      "metadata": {
        "id": "OsPO2nalh0Qb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Ridge Regression (L2) with GridSearchCV"
      ],
      "metadata": {
        "id": "WHqQ4wrycVG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline: scaling + Ridge regression\n",
        "ridge_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"ridge\", Ridge())\n",
        "])\n",
        "\n",
        "# Hyperparameter grid\n",
        "ridge_params = {\n",
        "    \"ridge__alpha\": [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Grid search with 5-fold cross-validation\n",
        "ridge_grid = GridSearchCV(\n",
        "    ridge_pipeline,\n",
        "    ridge_params,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "# Train GridSearch\n",
        "ridge_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Ridge Alpha:\", ridge_grid.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQK_iz9McYRH",
        "outputId": "92875e60-7da3-4b0e-d193-9850d58c2bcf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Ridge Alpha: {'ridge__alpha': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Lasso Regression (L1) with GridSearchCV"
      ],
      "metadata": {
        "id": "xx8NttI0ccoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline: scaling + Lasso regression\n",
        "lasso_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"lasso\", Lasso(max_iter=10000))\n",
        "])\n",
        "\n",
        "# Hyperparameter grid\n",
        "lasso_params = {\n",
        "    \"lasso__alpha\": [0.001, 0.01, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "lasso_grid = GridSearchCV(\n",
        "    lasso_pipeline,\n",
        "    lasso_params,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "lasso_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Lasso Alpha:\", lasso_grid.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8jeZAf5cuDP",
        "outputId": "5c3cd737-0d24-46d7-d1f3-18cec0d4e315"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Lasso Alpha: {'lasso__alpha': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Ridge (L2) vs Lasso (L1) Evaluation"
      ],
      "metadata": {
        "id": "xvDbG6tCc5dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best models\n",
        "best_ridge = ridge_grid.best_estimator_\n",
        "best_lasso = lasso_grid.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "ridge_pred = best_ridge.predict(X_test)\n",
        "lasso_pred = best_lasso.predict(X_test)\n",
        "\n",
        "# MSE comparison\n",
        "print(\"Ridge Test MSE:\", mean_squared_error(y_test, ridge_pred))\n",
        "print(\"Lasso Test MSE:\", mean_squared_error(y_test, lasso_pred))\n",
        "\n",
        "# Coefficient sparsity\n",
        "ridge_coef = best_ridge.named_steps[\"ridge\"].coef_\n",
        "lasso_coef = best_lasso.named_steps[\"lasso\"].coef_\n",
        "\n",
        "print(\"Non-zero Ridge coefficients:\", np.sum(ridge_coef != 0))\n",
        "print(\"Non-zero Lasso coefficients:\", np.sum(lasso_coef != 0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CTc5AlGc66M",
        "outputId": "d19684c9-a1ab-4259-cc22-81644580de41"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Test MSE: 0.062053145746705035\n",
            "Lasso Test MSE: 0.05837456845081737\n",
            "Non-zero Ridge coefficients: 30\n",
            "Non-zero Lasso coefficients: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Theory: Bias–Variance Tradeoff (Regression)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Method--------------------------Effect\n",
        "\n",
        "Ridge (L2)\t----------------------->Shrinks coefficients, reduces variance\n",
        "\n",
        "Lasso (L1)\t----------------------->Shrinks + sets some coefficients to zero\n",
        "\n",
        "Too much regularization\t--------->High bias, underfitting\n",
        "\n",
        "No regularization\t---------------->Low bias, high variance"
      ],
      "metadata": {
        "id": "A3PaI8CqjhXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7Q6aX2dbkhaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 2: CLASSIFICATION (BREAST CANCER)"
      ],
      "metadata": {
        "id": "2Dnacm3KdmFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Load and Split Dataset"
      ],
      "metadata": {
        "id": "TtQirZrOdqEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Breast Cancer dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training samples:\", X_train.shape)\n",
        "print(\"Testing samples:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "_7gi0DdjdvgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9e47bf-5acd-4c22-8150-f5efb7e6f2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: (455, 30)\n",
            "Testing samples: (114, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Baseline Logistic Regression"
      ],
      "metadata": {
        "id": "DOD3Xl7wdzc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression (default = L2 regularization)\n",
        "log_reg = LogisticRegression(max_iter=10000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = log_reg.predict(X_train)\n",
        "y_test_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Baseline Logistic Regression\")\n",
        "print(\"Train Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "print(log_reg.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0JxZWpdd0ea",
        "outputId": "4af7e28d-9585-4611-aa49-53ac947798c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Logistic Regression\n",
            "Train Accuracy: 0.9582417582417583\n",
            "Test Accuracy: 0.956140350877193\n",
            "Model Coefficients:\n",
            "[[ 1.0274368   0.22145051 -0.36213488  0.0254667  -0.15623532 -0.23771256\n",
            "  -0.53255786 -0.28369224 -0.22668189 -0.03649446 -0.09710208  1.3705667\n",
            "  -0.18140942 -0.08719575 -0.02245523  0.04736092 -0.04294784 -0.03240188\n",
            "  -0.03473732  0.01160522  0.11165329 -0.50887722 -0.01555395 -0.016857\n",
            "  -0.30773117 -0.77270908 -1.42859535 -0.51092923 -0.74689363 -0.10094404]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Logistic Regression :\n",
        "\n",
        "Uses sigmoid function\n",
        "\n",
        "Outputs probability\n",
        "\n",
        "Default L2 regularization\n",
        "\n",
        "Prevents exploding weights"
      ],
      "metadata": {
        "id": "Pa_GLdgkukZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Logistic Regression with L1/L2 & GridSearchCV (Hyperparameter Tuning (C & Penalty))"
      ],
      "metadata": {
        "id": "f3fQUIDMd5ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression pipeline\n",
        "log_pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"logreg\", LogisticRegression(\n",
        "        solver=\"liblinear\",\n",
        "        max_iter=10000\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Hyperparameter grid\n",
        "log_params = {\n",
        "    \"logreg__penalty\": [\"l1\", \"l2\"],\n",
        "    \"logreg__C\": [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "log_grid = GridSearchCV(\n",
        "    log_pipe,\n",
        "    log_params,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\"\n",
        ")\n",
        "\n",
        "log_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Logistic Params:\", log_grid.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMSSXDvZd-AK",
        "outputId": "93f28dd8-368e-482b-d8d0-1db27c4f46bb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Params: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: L1 vs L2 Final Evaluation"
      ],
      "metadata": {
        "id": "mrx_CKf5eMmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best logistic model\n",
        "best_log = log_grid.best_estimator_\n",
        "\n",
        "# Test accuracy\n",
        "y_test_pred = best_log.predict(X_test)\n",
        "print(\"Optimized Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Coefficient sparsity\n",
        "coef = best_log.named_steps[\"logreg\"].coef_\n",
        "print(\"Non-zero coefficients:\", np.sum(coef != 0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_6BW7KqeNjF",
        "outputId": "8c084f5a-4874-4de2-d9e3-3a658d6c7a61"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Test Accuracy: 0.9912280701754386\n",
            "Non-zero coefficients: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Theory: Bias–Variance Tradeoff (Classification)"
      ],
      "metadata": {
        "id": "4aNhXEWjnO5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. L1 Regularization\n",
        "\n",
        "* Feature selection\n",
        "\n",
        "* Sparse model\n",
        "\n",
        "* Higher bias, lower variance\n",
        "\n",
        "2. L2 Regularization\n",
        "\n",
        "* Keeps all features\n",
        "\n",
        "* Stable predictions\n",
        "\n",
        "* Balanced bias-variance\n",
        "\n",
        "3. C parameter\n",
        "\n",
        "* Small C → strong regularization\n",
        "\n",
        "* Large C → weak regularization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mYywwKXunRry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "* Baseline models overfit\n",
        "\n",
        "* Regularization improves generalization\n",
        "\n",
        "* Ridge is better when many features matter\n",
        "\n",
        "* Lasso is useful for feature selection\n",
        "\n",
        "* Cross-validation ensures robust hyperparameter choice"
      ],
      "metadata": {
        "id": "hM5XfTWfnmhI"
      }
    }
  ]
}